


# Importing Libraries 
from textblob import TextBlob
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
import re
from collections import Counter

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

sns.set()


with open('20th_century_events.txt', 'r', errors='ignore') as file:
    data = file.read().replace('\n', ' ')





from nltk.tokenize import sent_tokenize

tokenized_sent = sent_tokenize(data)

print(tokenized_sent[:10])





from nltk.tokenize import word_tokenize

tokenized_word = word_tokenize(data)

print(tokenized_word[:50])





from nltk.probability import FreqDist

dist_words = FreqDist(tokenized_word)

dist_words.most_common(10)





plt.figure(figsize=(8,3))
dist_words.plot(10)
plt.show()





from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))
print(stop_words)


# Removing stopwords in words

filtered_words = [] # creates an empty list
for word in tokenized_word:
    if word not in stop_words:
        filtered_words.append(word)


filtered_words


# Create a new FreqDist for filtered_words

dist_words_filter = FreqDist(filtered_words)
print(dist_words_filter)


# Frequency Distribution Plot
plt.figure(figsize=(8, 3))
dist_words_filter.plot(10, cumulative = False)
plt.show()


dist_words_filter





# Substitute all punctuations marks with a space 
sans_punc = re.sub("[^a-zA-Z]", " ", str(filtered_words))


sans_punc


# Tokenize Again
tokenized_word_2 = word_tokenize(sans_punc)


print(tokenized_word_2)


# Create a new FreqDist

dist_words_filter_2 = FreqDist(tokenized_word_2)


# Frequency Distribution Plot

plt.figure(figsize=(8, 3))
dist_words_filter_2.plot(30, cumulative = False)
plt.show()


dist_words_filter_2.most_common(20)





text = TextBlob(str(tokenized_word_2))

tags_list = text.tags





df_text = pd.DataFrame(tags_list)
df_text.columns = ['Words','Word type']

df_group = df_text.groupby('Word type').count().reset_index()

top20 = df_group.nlargest(20,'Words')





from textblob import TextBlob

blob = TextBlob(" ".join(tokenized_word_2))

tags_list = blob.tags

print(tags_list[:20])





from collections import Counter
import pandas as pd

pos_tags = [tag for word, tag in tags_list]

pos_counts = Counter(pos_tags)

top10_pos = pos_counts.most_common(10)

df_pos = pd.DataFrame(top10_pos, columns=["POS","Count"])

print(df_pos)





import seaborn as sns
import matplotlib.pyplot as plt

sns.barplot(data=df_pos, x="POS", y="Count")

plt.title("Top 10 POS Tags")
plt.show()





plt.figure(figsize=(10,5))

sns.barplot(
    x="Words",
    y="Word type",
    data=top20
)

plt.title("Top Word Types in 20th Century Events Text")
plt.show()





df_tags = pd.DataFrame(tags_list, columns=["Word","POS"])


# Nouns Plot
nouns = df_tags[df_tags["POS"].str.contains("NN")]

top_nouns = nouns["Word"].value_counts().head(15)

sns.barplot(x=top_nouns.index, y=top_nouns.values)

plt.xticks(rotation=90)
plt.title("Top Nouns")
plt.show()


# Verbs Plot
verbs = df_tags[df_tags["POS"].str.contains("VB")]

top_verbs = verbs["Word"].value_counts().head(15)

sns.barplot(x=top_verbs.index, y=top_verbs.values)

plt.xticks(rotation=90)
plt.title("Top Verbs")
plt.show()


# Adjectives Plot
adjs = df_tags[df_tags["POS"].str.contains("JJ")]

top_adjs = adjs["Word"].value_counts().head(15)

sns.barplot(x=top_adjs.index, y=top_adjs.values)

plt.xticks(rotation=90)
plt.title("Top Adjectives")
plt.show()





import seaborn as sns
import matplotlib.pyplot as plt

# Define the POS types we want to find
pos_types = [("NN", "Nouns"), ("VB", "Verbs"), ("JJ", "Adjectives")]

for pos_code, label in pos_types:
    # Filter df_tags for the specific Part of Speech
    filtered_df = df_tags[df_tags["POS"].str.contains(pos_code)]
    top_items = filtered_df["Word"].value_counts().head(15)
    
    # Create the plot
    plt.figure(figsize=(10, 5))
    sns.barplot(x=top_items.index, y=top_items.values, palette="magma")
    plt.xticks(rotation=45)
    plt.title(f"Top 15 {label}")
    plt.show()





# 1. Path is already correct based on your success message
path = r"C:\Users\ANITA BOADU\Twentieth Century Project\20th_century\countries_lookup.txt"

with open(path, "r", encoding="utf-8") as file:
    countries_lookup_list = [line.strip() for line in file if line.strip()]

# 2. Count mentions (Using .string to fix the AttributeError)
country_counts = {}
for country in countries_lookup_list:
    # We use text.string.lower() to access the raw text inside the TextBlob
    country_counts[country] = text.string.lower().count(country.lower())

# 3. Create the DataFrame
import pandas as pd
df_countries = pd.DataFrame(country_counts.items(), columns=["Country", "Mentions"])

# Display the dataframe to check results
df_countries.head(10)





import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
# This histogram shows how many countries were mentioned 0 times, 1 time, etc.
sns.histplot(df_countries['Mentions'], bins=10, kde=False, color="skyblue")

plt.title("Distribution of Country Mention Frequencies")
plt.xlabel("Number of Mentions")
plt.ylabel("Number of Countries")
plt.show()





#Sentiment Analysis
print(f"Polarity Score: {text.sentiment.polarity}")
print(f"Subjectivity Score: {text.sentiment.subjectivity}")





import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Create a dictionary with your specific results
sentiment_results = {
    'Metric': ['Polarity', 'Subjectivity'],
    'Score': [0.051627984748422645, 0.3581004052719376]
}

# 2. Convert to a DataFrame
df_sentiment = pd.DataFrame(sentiment_results)

# 3. Create the bar plot
plt.figure(figsize=(8, 6))
plot = sns.barplot(x='Metric', y='Score', data=df_sentiment, palette='viridis')

# 4. Add labels and a title
plt.title('Sentiment Analysis: Twentieth Century Key Events', fontsize=14)
plt.ylabel('Score Value')
plt.xlabel('') # Keeping it clean

# 5. Set the y-axis limits (Polarity is -1 to 1, Subjectivity is 0 to 1)
plt.ylim(-1, 1) 

# 6. Add a horizontal line at 0 for easy neutral reference
plt.axhline(0, color='black', linestyle='--', linewidth=1)

# Display the values on top of the bars
for p in plot.patches:
    plot.annotate(format(p.get_height(), '.2f'), 
                   (p.get_x() + p.get_width() / 2., p.get_height()), 
                   ha = 'center', va = 'center', 
                   xytext = (0, 9), 
                   textcoords = 'offset points')

plt.show()






